{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timothy Helton\n",
    "\n",
    "2018-06-26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "- This algorithm is ideal for **binary** classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomenclature\n",
    "\n",
    "- b: intercept parameter\n",
    "- J: cost function\n",
    "- L: loss function\n",
    "- w: weight parameters\n",
    "- X: matrix of all input vector instances\n",
    "    - each column is an instance\n",
    "- x: input vector for single instance\n",
    "- $\\hat{y}$: predicted output\n",
    "- $\\sigma$: sigmoid function or logistic function\n",
    "    - $\\sigma(z) = \\frac{1}{1 + e^{-z}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "1. A forward pass through the model is used to calculate the cost function.\n",
    "1. A backwards pass through the model updates the parameters by evaluating the gradient of the cost function.\n",
    "1. Once the parameters are trained the model is evaluated against the test dataset.\n",
    "1. If satisfied with the results from the training set apply the model to the validation set.\n",
    "1. Finally, the model is applied to unclassified data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Graph\n",
    "\n",
    "![Logistic Regression Computational Graph](images/logistic_regression_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "- b: intercept parameter\n",
    "    - $\\in\\mathbb{R}$\n",
    "- w: weight parameters\n",
    "    - $\\in\\mathbb{R}^{n_x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function\n",
    "\n",
    "- Used to train the parameters w and b.\n",
    "    - Influence of b on L\n",
    "        - $\\frac{\\partial L}{\\partial b}$\n",
    "    - Influence of w on L\n",
    "        - $\\frac{\\partial L}{\\partial w_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "$L(a, y) = -(y \\log{a} + (1 - y) \\log{(1 - a)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of Loss with respect to Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of Activation with respect to Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dervative of Model with respect to Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "- $\\hat{y}$: predicted output\n",
    "    - probability that y is equal to 1 given x\n",
    "        - $\\hat{y} = P(y=1 | x)$\n",
    "    - apply the sigmoid function to return a value between 0 and 1\n",
    "        - $\\hat{y} = \\sigma(w^{T}x + b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
