{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Model Build On Top of VGG 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Mean and Standard Deviation of Dataset\n",
    "\n",
    "Default ImageNet values over three channels:\n",
    "$$\\mu = (0.485, 0.456, 0.406)$$\n",
    "$$\\sigma = (0.229, 0.224, 0.225)$$\n",
    "\n",
    "These parameters are appropriate to use for transfer learning when the custom dataset is similar to the ImageNet dataset.\n",
    "\n",
    "#### Welford's Online Algorithm for Variance\n",
    "\n",
    "- *Online Algorithm*: An algorithm designed to process each new piece of data as it arrives to produce a final result without knowledge of any future data.\n",
    "- Calculates the standard deviation in one pass of the data eliminating the need to first cycle through the data to determine the mean.\n",
    "- Avoids the error found in naive variance calculations when the standard deviation is much smaller than the mean.\n",
    "\n",
    "[Welford, B.P., 1962. Note on a method for calculating corrected sums of squares and products. Technometrics, 4(3), pp.419-420.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.302.7503&rep=rep1&type=pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_mean_std(loader):\n",
    "    \"\"\"Compute the mean and standard deviation in an online fashion.\"\"\"\n",
    "    px_cnt = 0\n",
    "    moment_0 = torch.empty(3)\n",
    "    moment_1 = torch.empty(3)\n",
    "\n",
    "    for data in loader:\n",
    "        data = data[0]\n",
    "        batch, chanels, height, width = data.shape\n",
    "        total_pixels = px_cnt + batch * height * width\n",
    "        channel_sum = torch.sum(data, dim=[0, 2, 3])\n",
    "        channel_sum_squares = torch.sum(data ** 2, dim=[0, 2, 3])\n",
    "        moment_0 = (px_cnt * moment_0 + channel_sum) / total_pixels\n",
    "        moment_1 = (px_cnt * moment_1 + channel_sum_squares) / total_pixels\n",
    "        px_cnt = total_pixels\n",
    "\n",
    "    return moment_0, torch.sqrt(moment_1 - moment_0 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "Stats = namedtuple('Stats', 'mean, std')\n",
    "stats = {}\n",
    "\n",
    "train_data = datasets.ImageFolder(f'{data_dir}/train', transform=transforms.ToTensor())\n",
    "test_data = datasets.ImageFolder(f'{data_dir}/test', transform=transforms.ToTensor())\n",
    "\n",
    "stats = {}\n",
    "for dataset in (train_data, test_data):\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        num_workers=1,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    name = dataset.root.split('/')[-1]\n",
    "    stats[name] = Stats(*online_mean_std(loader))\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "batch_size = 32\n",
    "\n",
    "random_transforms = [\n",
    "    transforms.ColorJitter(\n",
    "        brightness=(0, 1),\n",
    "        contrast=0.5,\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "]\n",
    "shared_transforms = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=dataset_mean, std=dataset_std),\n",
    "]\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    ([transforms.RandomApply(random_transforms, p=0.5),\n",
    "      transforms.RandomResizedCrop(224),\n",
    "     ]\n",
    "     + shared_transforms)\n",
    ") \n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    ([transforms.Resize(255),\n",
    "      transforms.CenterCrop(224),\n",
    "     ]\n",
    "     + shared_transforms)\n",
    ")\n",
    "\n",
    "train_data = datasets.ImageFolder(f'{data_dir}/train',\n",
    "                                  transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(f'{data_dir}/test',\n",
    "                                 transform=test_transforms)\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Network Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG 16 Backbone\n",
    "\n",
    "Load the model and freeze the parameters so backprop will not apply to the backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure for CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Hardware Execution Mode: {str(device).upper()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Architecture\n",
    "\n",
    "Log softmax will be the output of the network to allow easy access to class probabilities during the evaulation step.\n",
    "This results in the criterion being the negative log likelihood loss `NLLLoss`.\n",
    "\n",
    "If the `CrossEntropyLoss` were to be used then the outputs would be values from the logits and which would require a transformation to yield probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"New classifier layers for model.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.category_cnt = 15\n",
    "        self.fc1 = nn.Linear(25088, 4096)\n",
    "        self.output = nn.Linear(4096, self.category_cnt)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Define forward pass through layers.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = F.log_softmax(self.output(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model.classifier = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.classifier.parameters(),\n",
    "    lr=0.003,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "eval_freq = 5\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = [x.to(device) for x in (inputs, labels)]        \n",
    "\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        steps += 1        \n",
    "        if steps % eval_freq == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = [x.to(device) for x in (inputs, labels)]\n",
    "        \n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            print(f\"\"\"\n",
    "                Epoch:         {epoch + 1}/{epochs}\n",
    "                Train Loss:    {running_loss / eval_freq:.3f}\n",
    "                Test Loss:     {test_loss / len(testloader):.3f}\n",
    "                Test Accuracy: {accuracy / len(testloader):.3f}\n",
    "            \"\"\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path()\n",
    "checkpoint_name = Path / 'custom_VGG16'\n",
    "time_stamp = dt.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "torch.save(model.state_dict(), f'{checkpoint_name}_{time_stamp}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
