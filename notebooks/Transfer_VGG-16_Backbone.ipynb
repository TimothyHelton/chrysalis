{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Model Build On Top of VGG 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Objective\n",
    "Create a pipeline to feed a neural network image classifier utilizing the VGG 16 backbone.\n",
    "\n",
    "- Data:\n",
    "    - [Kaggle Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/overview)\n",
    "- Inputs:\n",
    "    - NumPy arrays\n",
    "- Outputs:\n",
    "    - predicted class name\n",
    "    - probability of predicted class as a percentage\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import concurrent.futures\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Images to NumPy Arrays\n",
    "\n",
    "This is done only as an exercise to setup a pipeline based on NumPy arrays in lieu of PIL images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(im_file: Path):\n",
    "    \"\"\"Convert image file to NumPy array.\"\"\"\n",
    "    arr_file = im_file.with_suffix('.npy')\n",
    "    if not arr_file.is_file():\n",
    "        im = PIL.Image.open(im_file)\n",
    "        np.save(arr_file, np.array(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "im_files = {x.resolve() for x in Path(data_dir).glob('**/*') \n",
    "            if x.suffix in ('.jpeg', '.jpg', '.png')}\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    executor.map(image_to_array, im_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets\n",
    "\n",
    "##### Datasets From Images Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_im_data = datasets.ImageFolder(f'{data_dir}/train',\n",
    "                                     transform=transforms.ToTensor())\n",
    "test_im_data = datasets.ImageFolder(f'{data_dir}/test',\n",
    "                                    transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets From NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npy_loader(path: Path):\n",
    "    \"\"\"Helper function to load NumPy files into DataLoader.\"\"\"\n",
    "    arr = np.load(path).astype(np.float64)\n",
    "    np.divide(arr, 255.0, out=arr)\n",
    "    arr = np.moveaxis(arr, 2, 0)\n",
    "    return torch.from_numpy(arr).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.DatasetFolder(\n",
    "    root=f'{data_dir}/train',\n",
    "    loader=npy_loader,\n",
    "    extensions=('.npy'),\n",
    ")\n",
    "test_data = datasets.DatasetFolder(\n",
    "    root=f'{data_dir}/test', \n",
    "    loader=npy_loader,\n",
    "    extensions=('.npy'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Mean and Standard Deviation of Dataset\n",
    "\n",
    "Default ImageNet values over three channels:\n",
    "$$\\mu = (0.485, 0.456, 0.406)$$\n",
    "$$\\sigma = (0.229, 0.224, 0.225)$$\n",
    "\n",
    "These parameters are appropriate to use for transfer learning when the custom dataset is similar to the ImageNet dataset.\n",
    "\n",
    "#### Welford's Online Algorithm for Variance\n",
    "\n",
    "- *Online Algorithm*: An algorithm designed to process each new piece of data as it arrives to produce a final result without knowledge of any future data.\n",
    "- Calculates the standard deviation in one pass of the data eliminating the need to first cycle through the data to determine the mean.\n",
    "- Avoids the error found in naive variance calculations when the standard deviation is much smaller than the mean.\n",
    "\n",
    "[Welford, B.P., 1962. Note on a method for calculating corrected sums of squares and products. Technometrics, 4(3), pp.419-420.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.302.7503&rep=rep1&type=pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calaculate Dataset Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_mean_std(loader):\n",
    "    \"\"\"Compute the mean and standard deviation in an online fashion.\"\"\"\n",
    "    px_cnt = 0\n",
    "    moment_0 = torch.empty(3)\n",
    "    moment_1 = torch.empty(3)\n",
    "\n",
    "    for data in loader:\n",
    "        data = data[0]\n",
    "        batch, chanels, height, width = data.shape\n",
    "        total_pixels = px_cnt + batch * height * width\n",
    "        channel_sum = torch.sum(data, dim=[0, 2, 3])\n",
    "        channel_sum_squares = torch.sum(data ** 2, dim=[0, 2, 3])\n",
    "        moment_0 = (px_cnt * moment_0 + channel_sum) / total_pixels\n",
    "        moment_1 = (px_cnt * moment_1 + channel_sum_squares) / total_pixels\n",
    "        px_cnt = total_pixels\n",
    "\n",
    "    return moment_0, torch.sqrt(moment_1 - moment_0 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats = namedtuple('Stats', 'mean, std')\n",
    "\n",
    "stats = {}\n",
    "for dataset in (train_data, test_data):\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        num_workers=1,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    name = dataset.root.split('/')[-1]\n",
    "    stats[name] = Stats(*online_mean_std(loader))\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Channel Statistics\n",
    "    \n",
    "    Mean:\n",
    "    \\tTrain: {[f'{x:6f}' for x in stats['train'].mean.tolist()]}\n",
    "    \\tTest:  {[f'{x:6f}' for x in stats['test'].mean.tolist()]}\n",
    "    \n",
    "    Standard Deviation\n",
    "    \\tTrain: {[f'{x:6f}' for x in stats['train'].std.tolist()]}\n",
    "    \\tTest:  {[f'{x:6f}' for x in stats['test'].std.tolist()]}\n",
    "    \"\"\"\n",
    "    .replace(\"'\", '')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_transforms = [\n",
    "    transforms.ColorJitter(\n",
    "        brightness=(0.1, 0.9),\n",
    "        contrast=0.5,\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "]\n",
    "shared_transforms = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=stats['train'].mean, std=stats['train'].std),\n",
    "]\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    ([transforms.RandomApply(random_transforms, p=0.5),\n",
    "      transforms.RandomResizedCrop(224),\n",
    "     ]\n",
    "     + shared_transforms)\n",
    ") \n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    ([transforms.Resize(255),\n",
    "      transforms.CenterCrop(224),\n",
    "     ]\n",
    "     + shared_transforms)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Loaders\n",
    "\n",
    "##### Split Train Dataset into Train and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "\n",
    "train_qty = len(train_data)\n",
    "idx = list(range(train_qty))\n",
    "np.random.shuffle(idx)\n",
    "split = int(np.floor(validation_size * train_qty))\n",
    "train_idx, valid_idx = idx[split:], idx[:split]\n",
    "\n",
    "train_sampler, valid_sampler = [SubsetRandomSampler(x)\n",
    "                                for x in (train_idx, valid_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "workers = 0\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size,\n",
    "                         num_workers=workers, sampler=train_sampler)\n",
    "validloader = DataLoader(train_data, batch_size=batch_size,\n",
    "                         num_workers=workers, sampler=valid_sampler)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size,\n",
    "                        num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Plot image from Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy()\n",
    "    image = np.moveaxis(image, 0, 2)\n",
    "    \n",
    "    if normalize:\n",
    "        mean = stats['train'].mean.numpy()\n",
    "        std = stats['train'].std.numpy()\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    for border in ('top', 'right', 'left', 'bottom'):\n",
    "        ax.spines[border].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: BUG with NumPy array shapes\n",
    "dataiter  = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = {\n",
    "    'train': {'data': train_data, 'loader': trainloader},\n",
    "    'test': {'data': test_data, 'loader': testloader},\n",
    "}\n",
    "\n",
    "cols = 4\n",
    "for row, dataset in enumerate(sets):\n",
    "    dataiter = iter(sets[dataset]['loader'])\n",
    "    images, labels = dataiter.next()\n",
    "#     fig, ax = plt.subplots(figsize=(10, 3), ncols=cols)\n",
    "#     for idx in range(cols):\n",
    "#         category = sets[dataset]['data'].classes[labels[idx]]\n",
    "#         plot_image(\n",
    "#             images[idx],\n",
    "#             ax=ax[idx],\n",
    "#             title=category,\n",
    "#         )\n",
    "#         plt.suptitle(f'{dataset.capitalize()} Examples:',\n",
    "#                      fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Network Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG 16 Backbone\n",
    "\n",
    "Load the model and freeze the parameters so backprop will not apply to the backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure for CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Hardware Execution Mode: {str(device).upper()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Architecture\n",
    "\n",
    "Log softmax will be the output of the network to allow easy access to class probabilities during the evaulation step.\n",
    "This results in the criterion being the negative log likelihood loss `NLLLoss`.\n",
    "\n",
    "If the `CrossEntropyLoss` were to be used then the outputs would be values from the logits and which would require a transformation to yield probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"New classifier layers for model.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.category_cnt = 15\n",
    "        self.fc1 = nn.Linear(25088, 4096)\n",
    "        self.output = nn.Linear(4096, self.category_cnt)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Define forward pass through layers.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = F.log_softmax(self.output(x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "model.classifier = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.classifier.parameters(),\n",
    "    lr=0.003,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "eval_freq = 5\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = [x.to(device) for x in (inputs, labels)]        \n",
    "\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        steps += 1        \n",
    "        if steps % eval_freq == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = [x.to(device) for x in (inputs, labels)]\n",
    "        \n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += (torch.mean(equals.type(torch.FloatTensor))\n",
    "                                 .item())\n",
    "\n",
    "            print(f\"\"\"\n",
    "                Epoch:         {epoch + 1}/{epochs}\n",
    "                Train Loss:    {running_loss / eval_freq:.3f}\n",
    "                Test Loss:     {test_loss / len(testloader):.3f}\n",
    "                Test Accuracy: {accuracy / len(testloader):.3f}\n",
    "            \"\"\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path()\n",
    "checkpoint_name = Path / 'custom_VGG16'\n",
    "time_stamp = dt.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "torch.save(model.state_dict(), f'{checkpoint_name}_{time_stamp}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
